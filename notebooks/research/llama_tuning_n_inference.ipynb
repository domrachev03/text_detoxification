{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Llama2 7b tuning & inference"]},{"cell_type":"markdown","metadata":{},"source":["This is more about exploring the possibilities of finetuning than an actual solution. Nevertheless, all the metrics would be computed"]},{"cell_type":"markdown","metadata":{},"source":["## Llama2 7b tuning"]},{"cell_type":"markdown","metadata":{},"source":["For the tuning part, the resourses of the Kaggle or Colab seems not to be quite enough. Therefore, one need to seek for other sourses. \n","\n","I've decided to use service called [modal.com](https://modal.com/) and utilize their computational power to run the evaluations.\n"]},{"cell_type":"markdown","metadata":{},"source":["To gain access to the service, you have to:\n","1. Regiseter in modal.com (1 minute, requires GitHub authentication)\n","2. Enter secret from Huggingface (enter the hf token in the `HUGGINGFACE_TOKEN` field and name it `huggingface`).\n"," \n","Their tool is much easier to use via the terminal, so here is the list of commands to launch it in CLI (and corresponding cell with these commands):\n","```bash\n","pip install modal # the only dependency in the code\n","modal token new   # this will open modal's tab in the browser and automatically authorize you\n","modal run src/data/llama/train_modal.py --dataset llama2_dataset.py --base chat7 --run-id chat7-nontoxic\n","\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T22:02:17.086725Z","iopub.status.busy":"2023-10-31T22:02:17.086084Z","iopub.status.idle":"2023-10-31T22:02:57.663938Z","shell.execute_reply":"2023-10-31T22:02:57.662920Z","shell.execute_reply.started":"2023-10-31T22:02:17.086694Z"},"trusted":true},"outputs":[],"source":["!pip install peft\n","!pip install --upgrade bitsandbytes\n","!pip install --upgrade accelerate"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-31T22:02:57.666116Z","iopub.status.busy":"2023-10-31T22:02:57.665820Z","iopub.status.idle":"2023-10-31T22:03:10.227120Z","shell.execute_reply":"2023-10-31T22:03:10.226098Z","shell.execute_reply.started":"2023-10-31T22:02:57.666088Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","from collections.abc import Iterable\n","from tqdm.auto import trange\n","import torch\n","import numpy as np\n","import peft\n","import transformers, accelerate, bitsandbytes"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T22:03:10.229126Z","iopub.status.busy":"2023-10-31T22:03:10.228437Z","iopub.status.idle":"2023-10-31T22:03:10.240554Z","shell.execute_reply":"2023-10-31T22:03:10.239622Z","shell.execute_reply.started":"2023-10-31T22:03:10.229096Z"},"trusted":true},"outputs":[],"source":["def wrap_messages(msgs):\n","    B_INST, E_INST = \"[INST] \", \" [/INST]\"\n","    B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n","    prefixed_queries = [\n","        B_INST\n","        + B_SYS\n","        + \"You are a Twitch moderator that paraphrases sentences to be non-toxic.\\n\"\n","        + E_SYS\n","        + \"Could you paraphrase this: \"\n","        + msg\n","        + \"?\\n\"\n","        + E_INST\n","        for msg in msgs\n","    ]\n","    return prefixed_queries\n","\n","\n","def predict(requests, greb_answer = False, batch_size = 1, max_length = 64):\n","    requests = wrap_messages(requests)\n","    \n","    model = AutoModelForCausalLM.from_pretrained(\n","        'daryl149/llama-2-7b-chat-hf', \n","        load_in_4bit=True, \n","        bnb_4bit_compute_dtype=torch.float16\n","    )\n","    model.load_adapter('domrachev03/llama2_7b_detoxification')\n","    model.eval()\n","        \n","    tokenizer = AutoTokenizer.from_pretrained('daryl149/llama-2-7b-chat-hf')\n","    tokenizer.pad_token = tokenizer.eos_token\n","    \n","    \n","    results = []\n","    for i in trange(0, len(requests), batch_size):\n","        batch = [t for t in requests[i: i + batch_size]]\n","        inputs = tokenizer(\n","            batch, \n","            padding=True, \n","            truncation=True, \n","            max_length = max_length, \n","            return_tensors='pt'\n","        ).input_ids.to(model.device)\n","        \n","        with torch.no_grad():\n","            out = model.generate(inputs, max_new_tokens=max_length+1)\n","            decoded = [tokenizer.decode(out_i, skip_special_tokens=True,temperature=0) for out_i in out]\n","            \n","            if greb_answer:\n","                decoded = [decoded[i][len(batch[i]):decoded[i].find('</s>')] for i in range(batch_size)]\n","            results.extend(decoded)\n","    \n","    return results"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-31T22:03:10.243452Z","iopub.status.busy":"2023-10-31T22:03:10.243165Z","iopub.status.idle":"2023-10-31T22:05:05.044252Z","shell.execute_reply":"2023-10-31T22:05:05.043322Z","shell.execute_reply.started":"2023-10-31T22:03:10.243427Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7cac94490bad4b318a9f42c67b6c40b2","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e3a364c3c0f4014ac345838ca0ed911","version_major":2,"version_minor":0},"text/plain":["Downloading (…)model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46765663f9da47b4860da813aefc5308","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33a7647de0714c8aa26dd235016449b2","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e814d542c9e44ee8bebbe27f50f359f1","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f79b53ee36447ed81d7e0bfe4e1ba85","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8a3fcda5fc541e89caf42605e474e0c","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f4bf8fb2e444e00ab3eb8fd2e4b978a","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/adapter_config.json:   0%|          | 0.00/449 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3b3eb2dc63246e1807dfe8434a32384","version_major":2,"version_minor":0},"text/plain":["Downloading adapter_model.bin:   0%|          | 0.00/16.8M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e60cac0a158e4f1da85a7166e18986e8","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"057490721ef64e859c5f29555742b517","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd70cf731be94f17ab461a068267f1de","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b47ad5f9b4cc4eaa86884a77bd950607","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"214cabf288f0415791ca1871ba25226f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[\"you're crazy!\",\n"," 'this chair makes me crazy.',\n"," 'this sauce, I love it.',\n"," 'I hate gays.']"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["queries = ['Fuck you!', 'This freaking chair makes me nuts', 'This fucking sause, I love it', 'I hate gays']\n","\n","predict(queries, greb_answer=True, batch_size=2)"]},{"cell_type":"markdown","metadata":{},"source":["## Loading the dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T22:05:05.045950Z","iopub.status.busy":"2023-10-31T22:05:05.045584Z","iopub.status.idle":"2023-10-31T22:05:09.616238Z","shell.execute_reply":"2023-10-31T22:05:09.615352Z","shell.execute_reply.started":"2023-10-31T22:05:05.045914Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset parquet/domrachev03--toxic_comments_subset to /root/.cache/huggingface/datasets/parquet/domrachev03--toxic_comments_subset-482f891ea0d5a6ed/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74b5dae92c1547098dbca54a9ab4c6b7","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e8c362749074fed8631d7703f352f2f","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/34.5M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56cf67d9e32e46e29503569ea21a1f59","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/3.83M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"891c1d153ac145ed867cc93af7f54aee","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/domrachev03--toxic_comments_subset-482f891ea0d5a6ed/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8746aeabcbe3499fbfdcf7f815303d26","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import datasets\n","\n","dataset = datasets.load_dataset(\"domrachev03/toxic_comments_subset\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T22:07:34.702199Z","iopub.status.busy":"2023-10-31T22:07:34.701824Z","iopub.status.idle":"2023-10-31T22:07:34.710796Z","shell.execute_reply":"2023-10-31T22:07:34.709850Z","shell.execute_reply.started":"2023-10-31T22:07:34.702167Z"},"trusted":true},"outputs":[],"source":["n_test = 1000\n","test_subset = dataset['test'].select(range(n_test))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T22:07:34.891293Z","iopub.status.busy":"2023-10-31T22:07:34.891011Z","iopub.status.idle":"2023-10-31T22:32:02.347745Z","shell.execute_reply":"2023-10-31T22:32:02.346736Z","shell.execute_reply.started":"2023-10-31T22:07:34.891267Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93d0b91edd0148fd85ada178408a48dc","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5961e46d138142c99032c58c0a73e635","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["test_preds = predict([*test_subset['reference']], greb_answer=True, batch_size=10)"]},{"cell_type":"markdown","metadata":{},"source":["## Metrics & saving"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T22:37:00.606252Z","iopub.status.busy":"2023-10-31T22:37:00.605409Z","iopub.status.idle":"2023-10-31T22:37:13.071366Z","shell.execute_reply":"2023-10-31T22:37:13.070352Z","shell.execute_reply.started":"2023-10-31T22:37:00.606221Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Collecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.9.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Installing collected packages: evaluate\n","Successfully installed evaluate-0.4.1\n"]}],"source":["!pip install sacrebleu\n","!pip install evaluate"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T22:39:59.600708Z","iopub.status.busy":"2023-10-31T22:39:59.599636Z","iopub.status.idle":"2023-10-31T22:39:59.977721Z","shell.execute_reply":"2023-10-31T22:39:59.976514Z","shell.execute_reply.started":"2023-10-31T22:39:59.600659Z"},"trusted":true},"outputs":[],"source":["cleanup()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T22:40:11.727407Z","iopub.status.busy":"2023-10-31T22:40:11.727017Z","iopub.status.idle":"2023-10-31T22:40:11.746700Z","shell.execute_reply":"2023-10-31T22:40:11.745628Z","shell.execute_reply.started":"2023-10-31T22:40:11.727376Z"},"trusted":true},"outputs":[],"source":["import gc\n","import tqdm\n","from tqdm.auto import trange\n","import torch\n","import numpy as np\n","\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, \\\n","    RobertaTokenizer, RobertaForSequenceClassification\n","\n","import evaluate\n","\n","\n","def cleanup():\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","\n","\n","def get_toxicity(preds, soft=False):\n","    results = []\n","\n","    model_name = 'SkolkovoInstitute/roberta_toxicity_classifier'\n","\n","    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n","    model = RobertaForSequenceClassification.from_pretrained(model_name)\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    model.to(device)\n","\n","    model.eval()\n","    for i in tqdm.tqdm(range(0, len(preds), 1)):\n","        batch = tokenizer(preds[i:i + 1], return_tensors='pt', padding=True).to(device)\n","\n","        with torch.no_grad():\n","            logits = model(**batch).logits\n","            out = torch.softmax(logits, -1)[:, 1].cpu().numpy()\n","            results.append(out)\n","    return np.concatenate(results)\n","\n","\n","def get_sacrebleu(inputs, preds):\n","    metric = evaluate.load(\"sacrebleu\")\n","\n","    result = metric.compute(predictions=preds, references=inputs)\n","    return result['score']\n","\n","\n","def get_fluency(preds, soft=False):\n","    path = 'cointegrated/roberta-large-cola-krishna2020'\n","\n","    model = AutoModelForSequenceClassification.from_pretrained(path)\n","    tokenizer = AutoTokenizer.from_pretrained(path)\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    model.to(device)\n","\n","    results = []\n","    bs = 1\n","    for i in trange(0, len(preds), bs):\n","        batch = [t for t in preds[i: i + bs]]\n","        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors='pt').to(device)\n","        with torch.no_grad():\n","            out = torch.softmax(model(**inputs).logits, -1)[:, 0].cpu().numpy()\n","            results.append(out)\n","    return np.concatenate(results)\n","\n","\n","def compute_metrics(eval_preds, tokenizer=None, print_results=False):\n","    preds, labels = eval_preds\n","    \n","    if tokenizer is not None:\n","        detokenized_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","        detokenized_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    else:\n","        detokenized_preds = preds\n","        detokenized_labels = labels\n","\n","    results = {}\n","    toxicity_per_sent = get_toxicity(detokenized_preds)\n","    results['avg_toxic'] = sum(toxicity_per_sent) / len(toxicity_per_sent)\n","    cleanup()\n","\n","    results['bleu'] = get_sacrebleu(detokenized_labels, detokenized_preds) / 100\n","    cleanup()\n","\n","    fluency_per_sent = get_fluency(preds)\n","    results['fluency'] = sum(fluency_per_sent) / len(preds)\n","    cleanup()\n","\n","    # count metrics\n","    results['joint'] = sum(toxicity_per_sent * results['bleu'] * fluency_per_sent) / len(preds)\n","    if print_results:\n","        print(\"--------------\")\n","        print(\"Metric   | Value\")\n","        print(\"--------------\")\n","        print(f\"toxic    | {results['avg_toxic']:.2f}\")\n","        print(f\"bleu (n) | {results['bleu']:.2f}\")\n","        print(f\"fluency  | {results['fluency']:.2f}\")\n","        print(\"===============\")\n","        print(f\"Total    | {results['joint']:.2f}\")\n","        print(\"--------------\")\n","    return results"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T22:37:30.328096Z","iopub.status.busy":"2023-10-31T22:37:30.327265Z","iopub.status.idle":"2023-10-31T22:37:30.343751Z","shell.execute_reply":"2023-10-31T22:37:30.342941Z","shell.execute_reply.started":"2023-10-31T22:37:30.328062Z"},"trusted":true},"outputs":[],"source":["labels_list = [*test_subset['translation']]"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T22:40:19.680522Z","iopub.status.busy":"2023-10-31T22:40:19.680156Z","iopub.status.idle":"2023-10-31T22:41:41.393942Z","shell.execute_reply":"2023-10-31T22:41:41.392964Z","shell.execute_reply.started":"2023-10-31T22:40:19.680494Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1000/1000 [00:09<00:00, 105.50it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60c8044e67ed458faf2dcbe2fa464e02","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/628 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1bcca3f57b4f4de3b5b49d8c0a85fced","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6604b00af0254372ab6a4734fba1b5f6","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84563a3001404565ac35be623b1a04eb","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"792698961e1840c782b8cff3144bb8db","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37cfb0ad133041d58dbd7178da31f6f3","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"707fa7813c114153bff1a619f35aaed5","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1459ac2302414513a10348df2bb2071c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["--------------\n","Metric   | Value\n","--------------\n","toxic    | 0.28\n","bleu (n) | 0.21\n","fluency  | 0.88\n","===============\n","Total    | 0.05\n","--------------\n"]},{"data":{"text/plain":["{'avg_toxic': 0.28193867359716024,\n"," 'bleu': 0.2141521479259361,\n"," 'fluency': 0.8797155001051724,\n"," 'joint': 0.05208585016087908}"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["compute_metrics((test_preds, labels_list), print_results=True)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T22:47:50.153167Z","iopub.status.busy":"2023-10-31T22:47:50.152803Z","iopub.status.idle":"2023-10-31T22:47:50.176442Z","shell.execute_reply":"2023-10-31T22:47:50.175629Z","shell.execute_reply.started":"2023-10-31T22:47:50.153137Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Query</th>\n","      <th>Predictions</th>\n","      <th>Original values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>and he smoked all this shit himself.</td>\n","      <td>And he smoked it all himself.</td>\n","      <td>And smoked all of this weed by myself.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Mother told me that Dad, the oldest of five ch...</td>\n","      <td>T]Mother told me that Dad was the oldest of fi...</td>\n","      <td>my mother told me that Papa, the eldest of fiv...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>What the hell did you say to Garrett?</td>\n","      <td>what did you say to Garrett?</td>\n","      <td>what did you tell him?</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Otherwise, there could be a strong incentive f...</td>\n","      <td>ncentive for the issuer to deceive the investor.</td>\n","      <td>otherwise, the issuer could be highly motivate...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I've been a pig for 19 months.</td>\n","      <td>I've been a pig for 19 months.</td>\n","      <td>I'm a cop 1 9 months.</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>and by the time, the authorities would be usel...</td>\n","      <td>d by the time the authorities got there, they'...</td>\n","      <td>By that time, the organs would be of no use, s...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>oh, shit!</td>\n","      <td>Oh, my God!</td>\n","      <td>Oh no!</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Shake his fucking hand and we can all go home.</td>\n","      <td>shake his hand and we can all go home.</td>\n","      <td>to shake his hand and we can all go home happy.</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>people tend to be cruel to intellectually disa...</td>\n","      <td>People tend to be cruel to intellectually disa...</td>\n","      <td>People can be cruel to people intellectually c...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>all these things are dead.</td>\n","      <td>All this is dead.</td>\n","      <td>All this stuff is dead.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               Query  \\\n","0               and he smoked all this shit himself.   \n","1  Mother told me that Dad, the oldest of five ch...   \n","2              What the hell did you say to Garrett?   \n","3  Otherwise, there could be a strong incentive f...   \n","4                     I've been a pig for 19 months.   \n","5  and by the time, the authorities would be usel...   \n","6                                          oh, shit!   \n","7     Shake his fucking hand and we can all go home.   \n","8  people tend to be cruel to intellectually disa...   \n","9                         all these things are dead.   \n","\n","                                         Predictions  \\\n","0                      And he smoked it all himself.   \n","1  T]Mother told me that Dad was the oldest of fi...   \n","2                       what did you say to Garrett?   \n","3   ncentive for the issuer to deceive the investor.   \n","4                     I've been a pig for 19 months.   \n","5  d by the time the authorities got there, they'...   \n","6                                        Oh, my God!   \n","7             shake his hand and we can all go home.   \n","8  People tend to be cruel to intellectually disa...   \n","9                                  All this is dead.   \n","\n","                                     Original values  \n","0             And smoked all of this weed by myself.  \n","1  my mother told me that Papa, the eldest of fiv...  \n","2                             what did you tell him?  \n","3  otherwise, the issuer could be highly motivate...  \n","4                              I'm a cop 1 9 months.  \n","5  By that time, the organs would be of no use, s...  \n","6                                             Oh no!  \n","7    to shake his hand and we can all go home happy.  \n","8  People can be cruel to people intellectually c...  \n","9                            All this stuff is dead.  "]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","preds_dict = pd.DataFrame([[orig_i, pred_i, label_i] for orig_i, pred_i, label_i in zip(test_subset['reference'], test_preds, labels_list)], columns=['Query', 'Predictions', 'Original values'])\n","\n","preds_dict.head(10)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T22:49:08.161018Z","iopub.status.busy":"2023-10-31T22:49:08.160648Z","iopub.status.idle":"2023-10-31T22:49:08.178655Z","shell.execute_reply":"2023-10-31T22:49:08.177748Z","shell.execute_reply.started":"2023-10-31T22:49:08.160987Z"},"trusted":true},"outputs":[],"source":["preds_dict.to_csv('llama_test.csv')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
