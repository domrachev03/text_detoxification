{"cells":[{"cell_type":"markdown","metadata":{"id":"rEJBSTyZIrIb"},"source":["# T5 tuning & inference using Reinforcement Learning\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["All the finetuning before was a supervised one. That is, we tried to tune the models to give a response close to the one we provided them. The problem is -- this paraphrase was an output from other paraphraser. This might shadow the true potential of the considered model.\n","Another problem is that the loss function does not have any idea about the task we are trying to solve -- it just punishes the model for creating an output different from the one expected. It would be nice to specify directly to the model, what we want to get.\n","\n","Both these problems might be solved by an unusual method -- Reinforcement Learning. Thanks to the library [Transformer Reinforcement Learning](https://huggingface.co/docs/trl/index), I don't have to implement it from scratch. \n","\n","On top of the described features, if one decide to deploy this algorithm to the production, using RL would allow to implement Reinforcement Learning from [Human Feedback](https://huggingface.co/blog/rlhf).\n","\n","To implement this approach, let's take T5-small model once again and play around"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:10:08.487133Z","iopub.status.busy":"2023-11-03T11:10:08.486766Z","iopub.status.idle":"2023-11-03T11:11:41.022235Z","shell.execute_reply":"2023-11-03T11:11:41.020925Z","shell.execute_reply.started":"2023-11-03T11:10:08.487105Z"},"trusted":true},"outputs":[],"source":["!pip install -q datasets transformers[sentencepiece] sacrebleu\n","!pip install -q evaluate\n","!pip install -q langchain\n","!pip install -q sentence-transformers\n","# Note that the code does not work properly with up-to-date version, see: https://github.com/huggingface/trl/issues/679\n","!pip install -q git+http://github.com/huggingface/trl.git@b6b593d61af124bfda111c1cb1370d9166236ea5"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:11:41.024902Z","iopub.status.busy":"2023-11-03T11:11:41.024568Z","iopub.status.idle":"2023-11-03T11:11:41.058224Z","shell.execute_reply":"2023-11-03T11:11:41.057093Z","shell.execute_reply.started":"2023-11-03T11:11:41.024869Z"},"trusted":true},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:11:41.059929Z","iopub.status.busy":"2023-11-03T11:11:41.059625Z","iopub.status.idle":"2023-11-03T11:11:57.798487Z","shell.execute_reply":"2023-11-03T11:11:57.797530Z","shell.execute_reply.started":"2023-11-03T11:11:41.059902Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["# Necessary inputs\n","import warnings\n","\n","import gc\n","from datasets import load_dataset, load_metric\n","import transformers\n","import datasets\n","import random\n","import pandas as pd\n","import numpy as np\n","from IPython.display import display, HTML\n","from tqdm import tqdm\n","from tqdm.auto import trange\n","tqdm.pandas()\n","\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, \\\n","                         DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, \\\n","                         RobertaTokenizer, RobertaForSequenceClassification\n","import wandb\n","from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, AutoModelForSeq2SeqLMWithValueHead, set_seed\n","\n","import evaluate\n","warnings.filterwarnings('ignore')\n","transformers.logging.set_verbosity_warning()\n","transformers.logging.set_verbosity_error()"]},{"cell_type":"markdown","metadata":{},"source":["Very convinient dashboard:"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:16:58.886559Z","iopub.status.busy":"2023-11-03T11:16:58.885749Z","iopub.status.idle":"2023-11-03T11:17:33.524706Z","shell.execute_reply":"2023-11-03T11:17:33.523552Z","shell.execute_reply.started":"2023-11-03T11:16:58.886517Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.15.12 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.9"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231103_111702-909phemd</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/innopolis-university/uncategorized/runs/909phemd' target=\"_blank\">fine-dream-15</a></strong> to <a href='https://wandb.ai/innopolis-university/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/innopolis-university/uncategorized' target=\"_blank\">https://wandb.ai/innopolis-university/uncategorized</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/innopolis-university/uncategorized/runs/909phemd' target=\"_blank\">https://wandb.ai/innopolis-university/uncategorized/runs/909phemd</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/innopolis-university/uncategorized/runs/909phemd?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7beeea1dc100>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init()"]},{"cell_type":"markdown","metadata":{},"source":["# Part 1. Labelled tuning"]},{"cell_type":"markdown","metadata":{"id":"whPRbBNbIrIl"},"source":["## Loading the dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:17:33.527680Z","iopub.status.busy":"2023-11-03T11:17:33.527059Z","iopub.status.idle":"2023-11-03T11:17:36.498106Z","shell.execute_reply":"2023-11-03T11:17:36.496898Z","shell.execute_reply.started":"2023-11-03T11:17:33.527636Z"},"id":"IreSlFmlIrIm","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset parquet/domrachev03--toxic_comments_subset to /root/.cache/huggingface/datasets/parquet/domrachev03--toxic_comments_subset-480257536bff0e3f/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96452372fac74eb0a67e6b7a058f17bf","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fc7d2e41f5f4be0b19ad5b76fb46728","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/15.7M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a41303140ea46fbbd074c1a6418bb52","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/1.75M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a630e54ec0e843aa89ec487cbb5633c7","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/domrachev03--toxic_comments_subset-480257536bff0e3f/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"579dfabcdf07497f97b7218c852d7a41","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5c602fefc2e426cbb801bce20233d6f","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["transformers.set_seed(42)\n","dataset = datasets.load_dataset(\"domrachev03/toxic_comments_subset\")\n","metric = load_metric(\"sacrebleu\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:17:36.500891Z","iopub.status.busy":"2023-11-03T11:17:36.499732Z","iopub.status.idle":"2023-11-03T11:17:36.672776Z","shell.execute_reply":"2023-11-03T11:17:36.671644Z","shell.execute_reply.started":"2023-11-03T11:17:36.500846Z"},"trusted":true},"outputs":[],"source":["n_train = 10000\n","n_val = 1000\n","ds_subset = dataset['train'].select(range(n_train + n_val))\n","\n","dataset['train'] = ds_subset.select(range(n_train)) \n","dataset['val'] = ds_subset.select(range(n_train, n_train+n_val))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:17:36.675997Z","iopub.status.busy":"2023-11-03T11:17:36.675672Z","iopub.status.idle":"2023-11-03T11:17:36.788896Z","shell.execute_reply":"2023-11-03T11:17:36.787714Z","shell.execute_reply.started":"2023-11-03T11:17:36.675971Z"},"trusted":true},"outputs":[],"source":["max_input_length = 64\n","max_target_length = 64\n","batch_size = 128"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:17:36.790889Z","iopub.status.busy":"2023-11-03T11:17:36.790470Z","iopub.status.idle":"2023-11-03T11:17:36.912319Z","shell.execute_reply":"2023-11-03T11:17:36.911080Z","shell.execute_reply.started":"2023-11-03T11:17:36.790854Z"},"trusted":true},"outputs":[],"source":["# simple postprocessing for textgithub\n","def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [[label.strip()] for label in labels]\n","\n","    return preds, labels\n"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T12:56:06.779496Z","iopub.status.busy":"2023-11-03T12:56:06.778643Z","iopub.status.idle":"2023-11-03T12:56:14.844439Z","shell.execute_reply":"2023-11-03T12:56:14.843195Z","shell.execute_reply.started":"2023-11-03T12:56:06.779462Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3/3 [00:00<00:00, 84.16it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9f4df88a6f940d3bfbbf4167aae646c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["--------------\n","Metric   | Value\n","--------------\n","toxic    | 0.33\n","bleu (n) | 0.09\n","fluency  | 0.89\n","===============\n","Total    | 0.03\n","--------------\n"]}],"source":["def cleanup():\n","    '''Clean the RAM and VRAM from the trash'''\n","\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","\n","\n","def get_toxicity(preds, batch_size=1, device=None):\n","    '''Calculates toxicity of the corpus using RoBerta finetuned on toxicity classification.'''\n","\n","    results = []\n","\n","    model_name = 'SkolkovoInstitute/roberta_toxicity_classifier'\n","\n","    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n","    model = RobertaForSequenceClassification.from_pretrained(model_name)\n","    if device is None:\n","        device = 'cuda' if torch.cuda.is_available() else device\n","    model.to(device)\n","\n","    model.eval()\n","    for i in tqdm.tqdm(range(0, len(preds), batch_size)):\n","        batch = tokenizer(preds[i:i + batch_size], return_tensors='pt', max_length=-1, padding=True).to(device)\n","\n","        with torch.no_grad():\n","            logits = model(**batch).logits\n","            out = torch.softmax(logits, -1)[:, 1].cpu().numpy()\n","            results.append(out)\n","    return 1 - np.concatenate(results)\n","\n","\n","def get_sacrebleu(inputs, preds):\n","    '''Calculates sacrebleu score for the inputs and predictions'''\n","\n","    metric = evaluate.load(\"sacrebleu\")\n","\n","    result = metric.compute(predictions=preds, references=inputs)\n","    return result['score']\n","\n","\n","def get_fluency(preds, soft=False, batch_size=1, device=None):\n","    '''Calculates fluency of the corpus using RoBerta finetuned on CoLa dataset.'''\n","\n","    model_name = 'cointegrated/roberta-large-cola-krishna2020'\n","\n","    model = RobertaForSequenceClassification.from_pretrained(model_name)\n","    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n","    if device is None:\n","        device = 'cuda' if torch.cuda.is_available() else device\n","    device = device\n","    model.to(device)\n","\n","    results = []\n","    for i in trange(0, len(preds), batch_size):\n","        batch = [t for t in preds[i: i + batch_size]]\n","        inputs = tokenizer(batch, max_length=-1, padding=True, return_tensors='pt').to(device)\n","        with torch.no_grad():\n","            out = torch.softmax(model(**inputs).logits, -1)[:, 0].cpu().numpy()\n","            results.append(out)\n","    return np.concatenate(results)\n","\n","\n","def compute_metrics(eval_preds, tokenizer=None, print_results=False, batch_size=1, device='cuda', model_name=\"\"):\n","    ''' Computing metrics for the given data\n","\n","    Parameters:\n","    eval_preds=(preds, labels) -- tuple with predictions and labels\n","    tokenzier -- the tokenizer for the sequence. Default: None, and sequence is treated as decoded one\n","    model_name -- optional model name for fancy output printing. Defaul: empty'''\n","\n","    preds, labels = eval_preds\n","\n","    if tokenizer is not None:\n","        detokenized_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","        filtered_labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","        detokenized_labels = tokenizer.batch_decode(filtered_labels, skip_special_tokens=True)\n","    else:\n","        detokenized_preds = preds\n","        detokenized_labels = labels\n","\n","    results = {}\n","    results['toxic'] = get_toxicity(detokenized_preds, batch_size=batch_size, device=device)\n","    results['avg_toxic'] = sum(results['toxic']) / len(results['toxic'])\n","    cleanup()\n","\n","    results['bleu'] = get_sacrebleu(detokenized_labels, detokenized_preds) / 100\n","    cleanup()\n","\n","    results['fluency'] = get_fluency(detokenized_preds, batch_size=batch_size, device=device)\n","    results['avg_fluency'] = sum(results['fluency']) / len(results['fluency'])\n","    cleanup()\n","\n","    # count metrics\n","    results['joint'] = sum(results['toxic'] * results['bleu'] * results['fluency']) / len(preds)\n","    if print_results:\n","        if model_name != \"\":\n","            print(\"--------------\")\n","            print(model_name)\n","        print(\"--------------\")\n","        print(\"Metric   | Value\")\n","        print(\"--------------\")\n","        print(f\"toxic    | {results['avg_toxic']:.2f}\")\n","        print(f\"bleu (n) | {results['bleu']:.2f}\")\n","        print(f\"fluency  | {results['avg_fluency']:.2f}\")\n","        print(\"===============\")\n","        print(f\"Total    | {results['joint']:.2f}\")\n","        print(\"--------------\")\n","    return results\n"]},{"cell_type":"markdown","metadata":{},"source":["# T5-small"]},{"cell_type":"markdown","metadata":{},"source":["## Selecting the model\n","The baseline model is [`t5-small`](https://huggingface.co/docs/transformers/model_doc/t5) transformer. This acritecture seems suitable for our task, since: \"*T5 works well on a variety of tasks out-of-the-box by prepending a different prefix to the input corresponding to each task, e.g., for translation: translate English to German: ..., for summarization: summarize: ...*\""]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:17:37.050631Z","iopub.status.busy":"2023-11-03T11:17:37.050140Z","iopub.status.idle":"2023-11-03T11:17:37.165212Z","shell.execute_reply":"2023-11-03T11:17:37.164107Z","shell.execute_reply.started":"2023-11-03T11:17:37.050599Z"},"trusted":true},"outputs":[],"source":["# selecting model checkpoint\n","model_type = \"t5-small\""]},{"cell_type":"markdown","metadata":{},"source":["The model utilizes pretrained tokenizer"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:17:37.167018Z","iopub.status.busy":"2023-11-03T11:17:37.166652Z","iopub.status.idle":"2023-11-03T11:17:37.919825Z","shell.execute_reply":"2023-11-03T11:17:37.918680Z","shell.execute_reply.started":"2023-11-03T11:17:37.166985Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2503db6591b041e89fafd630d06438ba","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24ee5800dde34c048de5dd6649c6a593","version_major":2,"version_minor":0},"text/plain":["Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4fdbd42cb9604d87bd79eb0a03612cb1","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["t5_tokenizer = AutoTokenizer.from_pretrained(model_type, )\n","\n","def t5_wrapper(text):\n","    wrapped = f\"Make the following sentence non-toxic: '{text}'\"\n","    return wrapped\n","\n","def t5_preprocess_function(examples):\n","    inputs = t5_wrapper(examples[\"reference\"])\n","    targets = examples[\"translation\"]\n","    \n","    model_inputs = t5_tokenizer(inputs, max_length=max_input_length, truncation=True)\n","    labels = t5_tokenizer(targets, max_length=max_target_length, truncation=True)\n","\n","    return model_inputs\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:17:37.921759Z","iopub.status.busy":"2023-11-03T11:17:37.921384Z","iopub.status.idle":"2023-11-03T11:17:42.886824Z","shell.execute_reply":"2023-11-03T11:17:42.885660Z","shell.execute_reply.started":"2023-11-03T11:17:37.921729Z"},"id":"eXNLu_-nIrJI","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25edf79a53744726938a087a6a27039e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10000 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"}],"source":["t5_ds_train = dataset['train'].map(\n","    t5_preprocess_function, \n","    batched=False,\n","    load_from_cache_file=False,\n",")\n","t5_ds_train.set_format(type=\"torch\")"]},{"cell_type":"markdown","metadata":{},"source":["## T5 reinforcement learning"]},{"cell_type":"markdown","metadata":{},"source":["The `huggingface` provides a software for performing a [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index). However, it seems like this approach is highly uninvestigated (I've managed to find a few systematic reviews on the area). Hence, I decided to give it a try on a given task"]},{"cell_type":"markdown","metadata":{},"source":["## The metric"]},{"cell_type":"markdown","metadata":{},"source":["My approach of choosing the reward function was based on different combinations of these parameters:\n","1. *Toxicity*. It was evaluated using the RoBerta, finetuned for toxicity classification ([link](https://huggingface.co/s-nlp/roberta_toxicity_classifier_v1))\n","2. *Similarity*. It was evaluated using either [sacre bleu](https://huggingface.co/spaces/evaluate-metric/sacrebleu) metric or using cosine similarity metric.\n","3. *Fluency*. The fluency was evaluated via RoBerta, fituned on evaluation of language fluency, provided by the authors of the paper ([link](https://huggingface.co/cointegrated/roberta-large-cola-krishna2020)).\n","\n","I've tried many different metrics, this one impelents:\n","$$ R(p, l) =\n","  \\left\\{\n","  \\begin{aligned}\n","    \\text{toxic}(p) + \\text{fluency}(p) - 20, \\qquad& \\text{bleu}(p, l) < 0.2, \\\\\n","    \\text{toxic}(p) + \\text{fluency}(p), \\qquad& otherwise  .\n","  \\end{aligned}\n","  \\right.\n","$$\n","and would be considered in all further evaluations."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:17:42.891615Z","iopub.status.busy":"2023-11-03T11:17:42.891210Z","iopub.status.idle":"2023-11-03T11:17:43.545824Z","shell.execute_reply":"2023-11-03T11:17:43.544737Z","shell.execute_reply.started":"2023-11-03T11:17:42.891579Z"},"trusted":true},"outputs":[],"source":["from sentence_transformers import util\n","\n","def get_toxicity_reward(preds, batch_size=1):\n","    results = []\n","\n","    model_name = 'SkolkovoInstitute/roberta_toxicity_classifier'\n","\n","    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n","    model = RobertaForSequenceClassification.from_pretrained(model_name)\n","    device = 'cuda'\n","    model.to(device)\n","\n","    model.eval()\n","    for i in tqdm(range(0, len(preds), batch_size)):\n","        batch = tokenizer(preds[i:i + batch_size], return_tensors='pt', max_length=-1, padding=True).to(device)\n","\n","        with torch.no_grad():\n","            logits = model(**batch).logits\n","            out = logits[:, 0]\n","            results.append(out)\n","    return torch.concatenate(results)\n","\n","# def get_cosine_similarity_reward(inputs, preds):\n","#     return np.array([util.pytorch_cos_sim(in_i.type(torch.float64), pred_i.type(torch.float64)) for in_i, pred_i in zip(inputs, preds)])\n","\n","def get_sacrebleu(inputs, preds):\n","    metric = evaluate.load(\"sacrebleu\")\n","\n","    results = []\n","    for i in range(len(inputs)):\n","        results.append(metric.compute(predictions=preds[i:i+1], references=inputs[i:i+1])['score'])\n","    return torch.tensor(results).to('cuda')\n","\n","\n","def get_fluency_reward(preds, batch_size=1):\n","    path = 'cointegrated/roberta-large-cola-krishna2020'\n","\n","    model = RobertaForSequenceClassification.from_pretrained(path)\n","    tokenizer = AutoTokenizer.from_pretrained(path)\n","    device = 'cuda'\n","    model.to(device)\n","\n","    results = []\n","    for i in trange(0, len(preds), batch_size):\n","        batch = [t for t in preds[i: i + batch_size]]\n","        inputs = tokenizer(batch, max_length=-1, padding=True, return_tensors='pt').to(device)\n","        with torch.no_grad():\n","            out = model(**inputs).logits[:, 0]\n","            results.append(out)\n","    return torch.concatenate(results)\n","\n","\n","def compute_reward(preds, labels, batch_size=1):\n","    toxicity = get_toxicity_reward(preds, batch_size=batch_size)\n","    cleanup()\n","\n","    bleu = torch.where(get_sacrebleu(labels, preds) < 0.2, -20, 0)\n","    cleanup()\n","\n","    fluency = get_fluency_reward(preds, batch_size=batch_size)\n","    cleanup()\n","    return toxicity + bleu + fluency\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:17:43.548203Z","iopub.status.busy":"2023-11-03T11:17:43.547767Z","iopub.status.idle":"2023-11-03T11:18:11.601870Z","shell.execute_reply":"2023-11-03T11:18:11.600415Z","shell.execute_reply.started":"2023-11-03T11:17:43.548164Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e32f3187d664d759d3bc4234a680478","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba3613622ff44cfe8be3827e2cabcb6d","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e447fa01ec7b406a9addd6a5528b3eea","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91e7ce97b17b4c97abfaabed540a5951","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abab87c21bd147d0a726bae028b4d460","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc631a7c342042c8b5bce0d3d4539dd9","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73806df48cf447f6a8c68b49ed260af4","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"909b22cc356e4b7ba0653cc2a7a53302","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/628 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0841ac30be1497aa298b8a536cea63c","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da11078b7d72432687a5b54826012cf6","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f263ee2302e04c7782cae904907708d7","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"014c58d77275465b91ae92f17a879f9f","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6c1fb708a4e4479a2a1dba5af420a2f","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62aaece27c3a497aa14f4288e211029b","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9713a30725848ca948bafd623c15fd4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["tensor([ -2.0337, -14.2195], device='cuda:0')"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["compute_reward(\n","    ['fuck you, bitch, I love you!', '<extra_id_0>. Retest:</s>'], \n","    ['fuck you, bitch, I hate you!', 'I Love you so much I could not express it!'], \n","    batch_size=2\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## The train process"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:18:11.605505Z","iopub.status.busy":"2023-11-03T11:18:11.603435Z","iopub.status.idle":"2023-11-03T11:18:11.731513Z","shell.execute_reply":"2023-11-03T11:18:11.728252Z","shell.execute_reply.started":"2023-11-03T11:18:11.605464Z"},"trusted":true},"outputs":[],"source":["config = PPOConfig(\n","    model_name=\"t5-small\",\n","    learning_rate=1.41e-5,\n","    ppo_epochs=4,\n","    batch_size=128,\n","    log_with='wandb',\n",")\n","\n","set_seed(42)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:18:11.734319Z","iopub.status.busy":"2023-11-03T11:18:11.733502Z","iopub.status.idle":"2023-11-03T11:18:12.359172Z","shell.execute_reply":"2023-11-03T11:18:12.357721Z","shell.execute_reply.started":"2023-11-03T11:18:11.734266Z"},"trusted":true},"outputs":[],"source":["def collator(data):\n","    return dict((key, [d[key] for d in data]) for key in data[0])"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:18:12.361801Z","iopub.status.busy":"2023-11-03T11:18:12.361318Z","iopub.status.idle":"2023-11-03T11:18:12.484730Z","shell.execute_reply":"2023-11-03T11:18:12.483543Z","shell.execute_reply.started":"2023-11-03T11:18:12.361760Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['reference', 'translation', 'similarity', 'lenght_diff', 'ref_tox', 'trn_tox', 'input_ids', 'attention_mask'],\n","    num_rows: 10000\n","})"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["t5_ds_train"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:18:12.489260Z","iopub.status.busy":"2023-11-03T11:18:12.488167Z","iopub.status.idle":"2023-11-03T11:18:12.614634Z","shell.execute_reply":"2023-11-03T11:18:12.613279Z","shell.execute_reply.started":"2023-11-03T11:18:12.489227Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask'],\n","    num_rows: 10000\n","})"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["cols_to_remove = ['reference', 'translation', 'similarity', 'lenght_diff', 'ref_tox', 'trn_tox']\n","\n","t5_clean_ds = t5_ds_train.remove_columns(cols_to_remove)\n","\n","t5_clean_ds"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:18:12.616521Z","iopub.status.busy":"2023-11-03T11:18:12.616117Z","iopub.status.idle":"2023-11-03T11:18:18.206651Z","shell.execute_reply":"2023-11-03T11:18:18.205145Z","shell.execute_reply.started":"2023-11-03T11:18:12.616482Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7035b6d162a942fc978f447cb1979924","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e64c77e01fb04a88b65e6df1d657123d","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ef3a2d0543242a9a7d23a70bea95bdc","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e4a5358c2c44c20a96023a8053c74f7","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(config.model_name)\n","ref_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(config.model_name)\n","tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:18:18.208789Z","iopub.status.busy":"2023-11-03T11:18:18.208356Z","iopub.status.idle":"2023-11-03T11:18:55.906823Z","shell.execute_reply":"2023-11-03T11:18:55.905666Z","shell.execute_reply.started":"2023-11-03T11:18:18.208753Z"},"trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:909phemd) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">fine-dream-15</strong> at: <a href='https://wandb.ai/innopolis-university/uncategorized/runs/909phemd' target=\"_blank\">https://wandb.ai/innopolis-university/uncategorized/runs/909phemd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20231103_111702-909phemd/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:909phemd). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.15.12 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.9"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231103_111818-vz8mbrfm</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/innopolis-university/trl/runs/vz8mbrfm' target=\"_blank\">sandy-eon-31</a></strong> to <a href='https://wandb.ai/innopolis-university/trl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/innopolis-university/trl' target=\"_blank\">https://wandb.ai/innopolis-university/trl</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/innopolis-university/trl/runs/vz8mbrfm' target=\"_blank\">https://wandb.ai/innopolis-university/trl/runs/vz8mbrfm</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["ppo_trainer = PPOTrainer(config, model, ref_model, tokenizer, dataset=t5_clean_ds, data_collator=collator)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T11:18:55.908854Z","iopub.status.busy":"2023-11-03T11:18:55.908430Z","iopub.status.idle":"2023-11-03T12:35:50.202208Z","shell.execute_reply":"2023-11-03T12:35:50.200514Z","shell.execute_reply.started":"2023-11-03T11:18:55.908804Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/79 [00:00<?, ?it/s]\n","100%|██████████| 1/1 [00:00<00:00, 13.93it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6525acedadf343f7b4e4277e7697a290","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  1%|▏         | 1/79 [01:08<1:29:12, 68.62s/it]\n","100%|██████████| 1/1 [00:00<00:00, 14.10it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0911150b3b14b19b679bcec3735caa2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 2/79 [02:17<1:28:16, 68.79s/it]\n","100%|██████████| 1/1 [00:00<00:00, 15.07it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce77bc0319f04c5d8dd360ec684bf9b2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 3/79 [03:23<1:25:27, 67.47s/it]\n","100%|██████████| 1/1 [00:00<00:00, 13.88it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ecbcef0a6e74436a4b506e88b345250","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 4/79 [04:31<1:24:38, 67.71s/it]\n","100%|██████████| 1/1 [00:00<00:00, 16.61it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f976a409525f4ba7ae84813cb91fc2ff","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  6%|▋         | 5/79 [05:39<1:23:30, 67.72s/it]\n","100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"935642547aaf4b719ce2893618f6ab27","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 6/79 [06:45<1:21:56, 67.35s/it]\n","100%|██████████| 1/1 [00:00<00:00, 15.92it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b54f5a3ea8c4cf2a3a1bb0c62788196","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  9%|▉         | 7/79 [07:53<1:21:05, 67.58s/it]\n","100%|██████████| 1/1 [00:00<00:00, 13.64it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4b867eeb150492887309249fdc20388","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 8/79 [09:01<1:20:05, 67.68s/it]\n","100%|██████████| 1/1 [00:00<00:00, 14.90it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e614344c64847acb7ebf474cb72a52c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 11%|█▏        | 9/79 [10:08<1:18:41, 67.45s/it]\n","100%|██████████| 1/1 [00:00<00:00, 14.34it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e5f2ab23a36422fa030d96faf6c543a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 13%|█▎        | 10/79 [11:16<1:17:41, 67.56s/it]\n","100%|██████████| 1/1 [00:00<00:00, 15.01it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8999668bd3fd410ca24e2167388a9bb6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 11/79 [12:23<1:16:24, 67.41s/it]\n","100%|██████████| 1/1 [00:00<00:00, 16.29it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ccee87c9afc4cff86899f90acedc554","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 15%|█▌        | 12/79 [13:28<1:14:22, 66.60s/it]\n","100%|██████████| 1/1 [00:00<00:00, 16.60it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17d0a3fd7b1645028d7826833ce96821","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 16%|█▋        | 13/79 [14:34<1:13:00, 66.37s/it]\n","100%|██████████| 1/1 [00:00<00:00, 16.76it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4f45e3ac2214291b8df7901c00081b9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 18%|█▊        | 14/79 [15:36<1:10:28, 65.06s/it]\n","100%|██████████| 1/1 [00:00<00:00, 17.32it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dbdfbcd3272e492b8a7c10f5de9a9b2e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 19%|█▉        | 15/79 [16:37<1:08:17, 64.02s/it]\n","100%|██████████| 1/1 [00:00<00:00, 16.97it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35e97e752e384e31b52cf880c7989982","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 16/79 [17:40<1:06:40, 63.50s/it]\n","100%|██████████| 1/1 [00:00<00:00, 17.06it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"202e1a54542f47648b686ba129022ec9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 22%|██▏       | 17/79 [18:40<1:04:45, 62.66s/it]\n","100%|██████████| 1/1 [00:00<00:00, 16.91it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c33c92224bd14a5599b8dd436744d167","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 23%|██▎       | 18/79 [19:42<1:03:29, 62.44s/it]\n","100%|██████████| 1/1 [00:00<00:00, 17.02it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31c76e57374047999d8a75dbb71ac645","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 24%|██▍       | 19/79 [20:42<1:01:31, 61.53s/it]\n","100%|██████████| 1/1 [00:00<00:00, 16.76it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9e29028a380495eb2de7eb95015038f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 20/79 [21:45<1:00:56, 61.97s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.08it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f0ee5b4610945dc85270068e9330683","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 27%|██▋       | 21/79 [22:46<59:35, 61.65s/it]  \n","100%|██████████| 1/1 [00:00<00:00, 17.17it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b1e44c296f345bfa2a0f9b3f07814f0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 28%|██▊       | 22/79 [23:49<58:59, 62.09s/it]\n","100%|██████████| 1/1 [00:00<00:00, 16.51it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92264698dc8b4e73b2748f3a55044dd4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 29%|██▉       | 23/79 [24:51<57:58, 62.12s/it]\n","100%|██████████| 1/1 [00:00<00:00, 16.92it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04514405977a4433add5688d2e644323","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 24/79 [25:54<57:04, 62.27s/it]\n","100%|██████████| 1/1 [00:00<00:00, 16.90it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bfb0104e2dec467f9f45e58c94774c26","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 32%|███▏      | 25/79 [26:56<56:09, 62.39s/it]\n","100%|██████████| 1/1 [00:00<00:00, 16.77it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c299c0771a4466cb226da0623949eb1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 26/79 [27:58<54:59, 62.25s/it]\n","100%|██████████| 1/1 [00:00<00:00, 17.81it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30f7c224326746bcbb90be50f35e3b49","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 34%|███▍      | 27/79 [28:58<53:18, 61.52s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.09it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e068c5128fd4ddf9522e65ab951224d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 35%|███▌      | 28/79 [29:57<51:41, 60.81s/it]\n","100%|██████████| 1/1 [00:00<00:00, 17.26it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63e21a8efa3949a5bf7b0b368511d4c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 37%|███▋      | 29/79 [30:57<50:29, 60.58s/it]\n","100%|██████████| 1/1 [00:00<00:00, 17.81it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1eacb9526fcb4b60ae57962c8cd468a4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 38%|███▊      | 30/79 [31:58<49:28, 60.58s/it]\n","100%|██████████| 1/1 [00:00<00:00, 16.53it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6e91d1d8c774f1bb073af53c090352d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 39%|███▉      | 31/79 [32:58<48:24, 60.50s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.00it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1d0c06935934cb4b7acfa9271f1a460","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 41%|████      | 32/79 [33:58<47:13, 60.29s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.79it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1016984a522444d493f82fddb43e068f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 42%|████▏     | 33/79 [34:55<45:34, 59.45s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.59it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c580f88c8ee04993abb0c4164793e03e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 43%|████▎     | 34/79 [35:51<43:40, 58.24s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.01it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"caed2470f5a2411dab0268e156514725","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 44%|████▍     | 35/79 [36:48<42:32, 58.01s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.62it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e2c0141acd048bfafc075366d7b9819","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 46%|████▌     | 36/79 [37:47<41:47, 58.31s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.31it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a44d7dd904d444f902423b2e0efb717","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 47%|████▋     | 37/79 [38:44<40:28, 57.82s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.67it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ccf2ba54397e4ec39cfa3443f310bb9c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 48%|████▊     | 38/79 [39:42<39:39, 58.03s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.59it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ef715b38ee94cb79081cef0b92286b0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 49%|████▉     | 39/79 [40:41<38:46, 58.17s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.16it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3798b179f404ad3926c651836468e43","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 51%|█████     | 40/79 [41:37<37:26, 57.59s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.21it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09cbc9a83b3b41ebb06dc1f0b6101f56","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 52%|█████▏    | 41/79 [42:33<36:12, 57.16s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.57it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce62e4216baa4963b8aa561f96f37cbf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 53%|█████▎    | 42/79 [43:29<34:56, 56.66s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.91it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8d3586a50674218a52eeef1c1eef1c1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 54%|█████▍    | 43/79 [44:26<34:09, 56.93s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.81it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aedf6f1a6e6f4080b8b2113a73306da5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 56%|█████▌    | 44/79 [45:22<33:01, 56.62s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.50it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51922bfab57d41d4a3f5ab1222f6d916","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 57%|█████▋    | 45/79 [46:18<31:58, 56.42s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.15it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77b9acfced444f4088db1147eff47e12","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 58%|█████▊    | 46/79 [47:13<30:45, 55.92s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.84it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d044b478b0994f8bb0ea45089264f5aa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 59%|█████▉    | 47/79 [48:09<29:50, 55.96s/it]\n","100%|██████████| 1/1 [00:00<00:00, 20.38it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72a4c3ab6b5a4ee5975f6a108e954d8f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 61%|██████    | 48/79 [49:04<28:48, 55.77s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.66it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"334145ed2b544929914d1e266ba913fe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 62%|██████▏   | 49/79 [50:00<27:51, 55.73s/it]\n","100%|██████████| 1/1 [00:00<00:00, 20.21it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1553f683b2954d0cad34e9928029d3a6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 50/79 [50:57<27:04, 56.00s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.52it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"555d996ce5a843f4a4482ca6df1666da","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 65%|██████▍   | 51/79 [51:52<26:00, 55.73s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.48it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b7c6e40012046a8b1ec993deae13457","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 66%|██████▌   | 52/79 [52:48<25:08, 55.89s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.70it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52d93559ea994e16a8bb4f00b27f8ad7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 53/79 [53:43<24:05, 55.58s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.90it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6783c7256d1943acba60ea5acd3f2121","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 68%|██████▊   | 54/79 [54:38<23:03, 55.34s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.91it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40d7ac0afc7b45c8a52d14562bda1097","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 70%|██████▉   | 55/79 [55:34<22:17, 55.71s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.40it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd887b7dd03547198c331445cc951939","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 71%|███████   | 56/79 [56:29<21:15, 55.46s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.84it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc8d75b822d94692a04369b4ce695622","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 72%|███████▏  | 57/79 [57:25<20:24, 55.64s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.95it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e8d957747b145809cf8d479c0974496","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 73%|███████▎  | 58/79 [58:20<19:23, 55.42s/it]\n","100%|██████████| 1/1 [00:00<00:00, 21.47it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"551fe2b023a44f0d92afdda917bfc839","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 75%|███████▍  | 59/79 [59:14<18:18, 54.92s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.17it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5dd12f3c903c41a29c1cf59a56bd07b0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 76%|███████▌  | 60/79 [1:00:10<17:31, 55.36s/it]\n","100%|██████████| 1/1 [00:00<00:00, 21.44it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37b7e0332d32428cb75c8b35ee751c35","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 77%|███████▋  | 61/79 [1:01:07<16:42, 55.68s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.83it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7170b9484344379b8990c859b5ce716","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 78%|███████▊  | 62/79 [1:02:01<15:38, 55.20s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.39it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09a1fb5165984165a8aca9d7b66e6777","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 80%|███████▉  | 63/79 [1:02:57<14:48, 55.55s/it]\n","100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0749e4fe71274b5dbf524f3310aa8886","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 81%|████████  | 64/79 [1:03:52<13:49, 55.29s/it]\n","100%|██████████| 1/1 [00:00<00:00, 21.19it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b1041b3fc504dda90b0df86c9f81f47","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 82%|████████▏ | 65/79 [1:04:47<12:54, 55.31s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.42it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61941a1eff8d40eebf9c7cf7e691a104","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 84%|████████▎ | 66/79 [1:05:43<12:01, 55.52s/it]\n","100%|██████████| 1/1 [00:00<00:00, 20.76it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1b74dd3b6c742b4bc968e7c83c1f46f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 85%|████████▍ | 67/79 [1:06:37<10:59, 54.93s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.97it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"95ddbd35d2954b25b92cb150fc8f5377","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 86%|████████▌ | 68/79 [1:07:33<10:08, 55.33s/it]\n","100%|██████████| 1/1 [00:00<00:00, 18.73it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd4f0f5c60154f5295e5130cfeeaebf3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 69/79 [1:08:30<09:17, 55.73s/it]\n","100%|██████████| 1/1 [00:00<00:00, 22.14it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a592d0e30e6545179bd1263bc6371093","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 89%|████████▊ | 70/79 [1:09:23<08:14, 54.98s/it]\n","100%|██████████| 1/1 [00:00<00:00, 20.25it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5dc89ca6d644164a64f6202c9ed7336","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 90%|████████▉ | 71/79 [1:10:18<07:20, 55.02s/it]\n","100%|██████████| 1/1 [00:00<00:00, 20.39it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d872676473442a49e615e383269f0a7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 72/79 [1:11:13<06:24, 54.96s/it]\n","100%|██████████| 1/1 [00:00<00:00, 19.81it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c958f1ab75d4812b808f61ce0e779c9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 92%|█████████▏| 73/79 [1:12:08<05:30, 55.11s/it]\n","100%|██████████| 1/1 [00:00<00:00, 20.49it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17deb4485fe8409e81ae67e4453e3061","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 94%|█████████▎| 74/79 [1:13:04<04:36, 55.38s/it]\n","100%|██████████| 1/1 [00:00<00:00, 21.50it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d30a4b4e3f74a78919f8b7c53e73396","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▍| 75/79 [1:14:00<03:41, 55.37s/it]\n","100%|██████████| 1/1 [00:00<00:00, 22.10it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44f6444dcdc346339f089b2106b9cf33","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 96%|█████████▌| 76/79 [1:14:55<02:46, 55.33s/it]\n","100%|██████████| 1/1 [00:00<00:00, 21.22it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"425d46f493f244938510eacfe9447a2c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 97%|█████████▋| 77/79 [1:15:50<01:50, 55.40s/it]\n","100%|██████████| 1/1 [00:00<00:00, 20.57it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"967921009e064f789094152f7f035ff8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 99%|█████████▊| 78/79 [1:16:44<00:54, 54.87s/it]\n","100%|██████████| 1/1 [00:00<00:00, 50.56it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de3c39fd902643a7b0615706f663a02f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 99%|█████████▊| 78/79 [1:16:53<00:59, 59.15s/it]\n"]},{"ename":"ValueError","evalue":"Batch size (128) does not match number of examples - but got 16 for: queries","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m rewards \u001b[38;5;241m=\u001b[39m compute_reward(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m], batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     25\u001b[0m rewards \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor([reward]) \u001b[38;5;28;01mfor\u001b[39;00m reward \u001b[38;5;129;01min\u001b[39;00m rewards]\n\u001b[0;32m---> 27\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mppo_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m ppo_trainer\u001b[38;5;241m.\u001b[39mlog_stats(stats, batch, rewards)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:429\u001b[0m, in \u001b[0;36mPPOTrainer.step\u001b[0;34m(self, queries, responses, scores)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;124;03mRun a PPO optimisation step given a list of queries, model responses, and rewards.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m    `dict[str, Any]`: A summary of the training statistics\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    427\u001b[0m bs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m--> 429\u001b[0m queries, responses, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_safety_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    432\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:389\u001b[0m, in \u001b[0;36mPPOTrainer._step_safety_checker\u001b[0;34m(self, batch_size, queries, responses, scores)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElements in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must tensors - got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor_list[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor_list) \u001b[38;5;241m!=\u001b[39m batch_size:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) does not match number of examples - but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(tensor_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# add queries, scores and responses on the correct device\u001b[39;00m\n\u001b[1;32m    394\u001b[0m queries \u001b[38;5;241m=\u001b[39m [tensor\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m queries]\n","\u001b[0;31mValueError\u001b[0m: Batch size (128) does not match number of examples - but got 16 for: queries"]}],"source":["generation_kwargs = {\n","    \"top_k\": 0.0,\n","    \"top_p\": 1.0,\n","    \"do_sample\": True,\n","    \"min_new_tokens\": 4\n","}\n","\n","stat_logs = []\n","batch_log = []\n","rewards_log = []\n","for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader), total=len(ppo_trainer.dataloader)):\n","    query_tensors = batch[\"input_ids\"]\n","    #### Get response from t5\n","    response_tensors = []\n","    for query in query_tensors:\n","        response = ppo_trainer.generate(query, **generation_kwargs)\n","        response_tensors.append(response.squeeze())\n","    batch[\"response\"] = [tokenizer.decode(r[1:].squeeze()) for r in response_tensors]\n","    \n","    # response = ppo_trainer.generate(query_tensors, **generation_kwargs)  \n","    # batch[\"response\"] = [tokenizer.decode(r[1:]) for r in response]\n","    batch['query'] = [tokenizer.decode(inp) for inp in batch['input_ids']]\n","    batch['query'] = [q[q.find('\\'')+1: q.rfind('\\'')] for q in batch['query']]\n","    rewards = compute_reward(batch['response'], batch['query'], batch_size=batch_size)\n","    rewards = [torch.tensor([reward]) for reward in rewards]\n","\n","    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n","    ppo_trainer.log_stats(stats, batch, rewards)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T12:52:47.931705Z","iopub.status.busy":"2023-11-03T12:52:47.930806Z","iopub.status.idle":"2023-11-03T12:52:48.434302Z","shell.execute_reply":"2023-11-03T12:52:48.433141Z","shell.execute_reply.started":"2023-11-03T12:52:47.931660Z"},"trusted":true},"outputs":[],"source":["model.save_pretrained(\"t5_rl_best\", push_to_hub=False)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-11-03T12:44:12.287344Z","iopub.status.busy":"2023-11-03T12:44:12.286503Z","iopub.status.idle":"2023-11-03T12:44:12.404089Z","shell.execute_reply":"2023-11-03T12:44:12.402647Z","shell.execute_reply.started":"2023-11-03T12:44:12.287309Z"}},"source":["## Evaluation"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T12:55:04.374456Z","iopub.status.busy":"2023-11-03T12:55:04.373681Z","iopub.status.idle":"2023-11-03T12:55:42.313554Z","shell.execute_reply":"2023-11-03T12:55:42.312467Z","shell.execute_reply.started":"2023-11-03T12:55:04.374417Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f4803b6f0564c858b1ba9b602e9fdc3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/136 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model.from_pretrained('domrachev03/t5_rl_detox')\n","model.eval()\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","results = []\n","msgs = [t5_wrapper(text) for text in dataset[\"test\"][\"reference\"]]\n","for i in trange(0, len(msgs), batch_size):\n","    batch = msgs[i: i+batch_size]\n","    tokenized_batch = tokenizer(batch, max_length=128, padding=True, return_tensors='pt').to(device)\n","    with torch.no_grad():\n","        output = model.generate(tokenized_batch['input_ids'])\n","        result = [tokenizer.decode(out_i, skip_special_tokens=True,temperature=0) for out_i in output]\n","    results.extend(result)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T12:56:22.898391Z","iopub.status.busy":"2023-11-03T12:56:22.897629Z","iopub.status.idle":"2023-11-03T12:57:23.745831Z","shell.execute_reply":"2023-11-03T12:57:23.744809Z","shell.execute_reply.started":"2023-11-03T12:56:22.898358Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 136/136 [00:14<00:00,  9.27it/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25ddb25a99da4240b4fd28a664361813","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/136 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["--------------\n","Metric   | Value\n","--------------\n","toxic    | 0.93\n","bleu (n) | 0.03\n","fluency  | 0.49\n","===============\n","Total    | 0.01\n","--------------\n"]},{"data":{"text/plain":["{'toxic': array([0.99982816, 0.99994403, 0.9999064 , ..., 0.99994403, 0.99994403,\n","        0.99982816], dtype=float32),\n"," 'avg_toxic': 0.9251211043690382,\n"," 'bleu': 0.02733905992001097,\n"," 'fluency': array([0.06736284, 0.9749654 , 0.06025813, ..., 0.9749654 , 0.9749654 ,\n","        0.06736284], dtype=float32),\n"," 'avg_fluency': 0.48509223179666894,\n"," 'joint': 0.011723955617528401}"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["compute_metrics((results, dataset['test']['translation']), print_results=True, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["## Saving"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save_pretrained('domrachev03/t5_rl_detox')"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T12:58:12.809518Z","iopub.status.busy":"2023-11-03T12:58:12.809118Z","iopub.status.idle":"2023-11-03T12:58:13.001237Z","shell.execute_reply":"2023-11-03T12:58:13.000294Z","shell.execute_reply.started":"2023-11-03T12:58:12.809487Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Query</th>\n","      <th>Predictions</th>\n","      <th>Labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>If they say they don't want your help, you can...</td>\n","      <td>the following sentence non-toxic.</td>\n","      <td>if they say they don't need help, you can bet ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>When you go home, they'il call you \"Mr. No-Leg...</td>\n","      <td>non-toxic.</td>\n","      <td>when you get home, they'll call you Mr.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Mrs. Sanders ain't goingfor that late shit no ...</td>\n","      <td>the sentence non-toxic.</td>\n","      <td>Mrs. Sanders is not curious about being late.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I want every bloody one of them to hear.</td>\n","      <td>the sentence non-toxic.</td>\n","      <td>I want everyone to hear it.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>That shit hurt.</td>\n","      <td>.</td>\n","      <td>and that really hurts.</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>How do I know if I tell you what you need to k...</td>\n","      <td>non-toxic.</td>\n","      <td>how do I know if I tell you what you want to k...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>This guy ain't going nowhere. Oh, shit!</td>\n","      <td>the following sentence non-toxic!</td>\n","      <td>this guy's not going anywhere.</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Fucked if I can remember.</td>\n","      <td>.</td>\n","      <td>if only I could remember.</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>I fucked one stitch and he looks at me now as ...</td>\n","      <td>'I made the following sentence non-toxic: I ma...</td>\n","      <td>I mess up a suture, and now he's looking at me...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Earth! Meet my lovely assistant... Tiny tits.</td>\n","      <td>the following sentence non-toxic.</td>\n","      <td>please welcome my beautiful assistant, Maloprs...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               Query  \\\n","0  If they say they don't want your help, you can...   \n","1  When you go home, they'il call you \"Mr. No-Leg...   \n","2  Mrs. Sanders ain't goingfor that late shit no ...   \n","3           I want every bloody one of them to hear.   \n","4                                    That shit hurt.   \n","5  How do I know if I tell you what you need to k...   \n","6            This guy ain't going nowhere. Oh, shit!   \n","7                          Fucked if I can remember.   \n","8  I fucked one stitch and he looks at me now as ...   \n","9      Earth! Meet my lovely assistant... Tiny tits.   \n","\n","                                         Predictions  \\\n","0                  the following sentence non-toxic.   \n","1                                         non-toxic.   \n","2                            the sentence non-toxic.   \n","3                            the sentence non-toxic.   \n","4                                                  .   \n","5                                         non-toxic.   \n","6                  the following sentence non-toxic!   \n","7                                                  .   \n","8  'I made the following sentence non-toxic: I ma...   \n","9                  the following sentence non-toxic.   \n","\n","                                              Labels  \n","0  if they say they don't need help, you can bet ...  \n","1            when you get home, they'll call you Mr.  \n","2      Mrs. Sanders is not curious about being late.  \n","3                        I want everyone to hear it.  \n","4                             and that really hurts.  \n","5  how do I know if I tell you what you want to k...  \n","6                     this guy's not going anywhere.  \n","7                          if only I could remember.  \n","8  I mess up a suture, and now he's looking at me...  \n","9  please welcome my beautiful assistant, Maloprs...  "]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","preds_dict = pd.DataFrame([[orig_i, pred_i, label_i] for orig_i, pred_i, label_i in zip(dataset['test']['reference'], results, dataset['test']['translation'])], columns=['Query', 'Predictions', 'Labels'])\n","\n","preds_dict.head(10)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T12:58:19.444435Z","iopub.status.busy":"2023-11-03T12:58:19.443629Z","iopub.status.idle":"2023-11-03T12:58:19.692812Z","shell.execute_reply":"2023-11-03T12:58:19.691882Z","shell.execute_reply.started":"2023-11-03T12:58:19.444370Z"},"trusted":true},"outputs":[],"source":["preds_dict.to_csv('t5_rl_test.csv')"]}],"metadata":{"colab":{"name":"Translation","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
